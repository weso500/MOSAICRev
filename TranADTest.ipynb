{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1FpbFEo1iYkHKojUs5RMdkxBJ7mFs-auN",
      "authorship_tag": "ABX9TyNzS71Y5XhRsEH7c2d8F2u3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weso500/MOSAICRev/blob/main/TranADTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Colab Setup: Run this cell first ---\n",
        "!pip install torch numpy pandas scikit-learn\n",
        "!mkdir -p '/content/drive/MyDrive/Globecom Paper/For Jason/IOT-Anomaly-Detection/Raw_Data'\n",
        "# # You must manually upload your RFQ.npy and RFQ_labels.npy files\n",
        "# # to the 'Raw_Data' directory in your Colab environment.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzH5ervvTuBb",
        "outputId": "dd087e09-fbbf-4304-ea80-84ff75f1655a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time\n",
        "\n",
        "# --- Colab Setup: Run this cell first ---\n",
        "# NOTE: The pip install and mkdir commands are assumed to have been run successfully.\n",
        "# !pip install torch numpy pandas scikit-learn\n",
        "# !mkdir -p '/content/drive/MyDrive/Globecom Paper/For Jason/IOT-Anomaly-Detection/Raw_Data'\n",
        "\n",
        "# --- Step 1: Mount Google Drive (Essential for accessing files) ---\n",
        "try:\n",
        "    print(\"Mounting Google Drive...\")\n",
        "    # Using 'force_remount=True' is often necessary if the notebook has disconnected/reconnected\n",
        "    # drive.mount('/content/drive', force_remount=True)\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting Google Drive: {e}\")\n",
        "\n",
        "\n",
        "# --- 2. CONFIGURATION ---\n",
        "SYSTEM = 'RFQ'\n",
        "# IMPORTANT: Full Google Drive path for correct file access\n",
        "RAW_DATA_DIR = '/content/drive/MyDrive/Globecom Paper/For Jason/IOT-Anomaly-Detection/Raw_Data'\n",
        "WINDOW_SIZE = 100         # Sequence length (L) for the Transformer\n",
        "N_FEATURES = 14           # Dimension of the feature vector (D_model)\n",
        "PREDICTION_LENGTH = 1     # Target sequence length (1 for anomaly detection)\n",
        "N_EPOCHS = 20             # Number of training epochs\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "# Transformer Hyperparameters\n",
        "D_MODEL = N_FEATURES      # Embedding dimension\n",
        "N_HEADS = 2               # Number of attention heads\n",
        "N_LAYERS = 2              # Number of encoder/decoder layers\n",
        "DROPOUT = 0.1\n",
        "\n",
        "# --- 3. DATA UTILITIES ---\n",
        "\n",
        "def load_and_preprocess_data(system, raw_data_dir):\n",
        "    \"\"\"Loads, splits, and preprocesses the accelerator data.\"\"\"\n",
        "    print(f\"Loading data for system: {system}\")\n",
        "\n",
        "    # Construct full paths based on the configured RAW_DATA_DIR\n",
        "    x_path = os.path.join(raw_data_dir, f'{system}.npy')\n",
        "    y_path = os.path.join(raw_data_dir, f'{system}_labels.npy')\n",
        "\n",
        "    X, Y = None, None\n",
        "\n",
        "    if not os.path.exists(x_path) or not os.path.exists(y_path):\n",
        "        print(f\"--- WARNING: Data files not found. Creating DUMMY DATA. ---\")\n",
        "        # Creating dummy data (1000 pulses, 200 time steps, 14 features)\n",
        "        X = np.random.rand(1000, 200, N_FEATURES)\n",
        "        # Dummy labels matching the expected structure (index, type, subtype)\n",
        "        Y = np.array([[i, 'Run', 'type'] for i in range(800)] +\n",
        "                     [[i + 800, 'Fault', 'type'] for i in range(200)], dtype=object)\n",
        "    else:\n",
        "        # --- FIX FOR OBJECT ARRAY ERROR ---\n",
        "        try:\n",
        "            # Attempt to load data with default settings\n",
        "            X = np.load(x_path)\n",
        "            Y = np.load(y_path, allow_pickle=True)\n",
        "            print(\"Real data loaded successfully.\")\n",
        "        except ValueError as e:\n",
        "            # This catch block specifically addresses the error you encountered.\n",
        "            print(f\"\\n--- ERROR HANDLING: Caught ValueError during loading: {e} ---\")\n",
        "            print(\"Attempting to reload data with explicit allow_pickle=True for both files.\")\n",
        "            try:\n",
        "                # Reload, forcing allow_pickle=True for the data file too, just in case.\n",
        "                X = np.load(x_path, allow_pickle=True)\n",
        "                Y = np.load(y_path, allow_pickle=True)\n",
        "                # Verify the structure to ensure loading was correct\n",
        "                if X.ndim < 2 or Y.dtype != object:\n",
        "                    print(\"WARNING: Data structure seems unusual after pickling. Proceeding...\")\n",
        "                print(\"Reload successful using allow_pickle=True.\")\n",
        "            except Exception as inner_e:\n",
        "                print(f\"CRITICAL ERROR: Failed to load data even with allow_pickle=True. {inner_e}\")\n",
        "                raise inner_e # Re-raise the error to stop execution\n",
        "\n",
        "    # Check if data was loaded/created successfully\n",
        "    if X is None or Y is None:\n",
        "        raise RuntimeError(\"Data failed to load or create dummy data.\")\n",
        "\n",
        "    # Identify normal and fault pulses based on the second column of Y (['Run', 'Fault'])\n",
        "    fault_indices, normal_indices = np.where(Y[:,1] == 'Fault')[0], np.where(Y[:,1] == 'Run')[0]\n",
        "    Xnormal = X[normal_indices, :, :]\n",
        "    Xfault = X[fault_indices, :, :]\n",
        "\n",
        "    print(f\"Normal Data Pulses: {len(Xnormal)}, Fault Data Pulses: {len(Xfault)}\")\n",
        "\n",
        "    # 1. CONCATENATE ALL PULSES INTO A SINGLE LONG TIME SERIES (MTS)\n",
        "    n_pulses, n_times, n_features = Xnormal.shape\n",
        "    X_mts = Xnormal.reshape(-1, n_features)\n",
        "\n",
        "    # 2. STANDARDIZATION (Fit only on normal training data)\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X_mts)\n",
        "    print(f\"Concatenated and Scaled MTS shape: {X_scaled.shape}\")\n",
        "\n",
        "    # Process Fault Data (for testing) using the scaler fitted on normal data\n",
        "    X_fault_mts = Xfault.reshape(-1, n_features)\n",
        "    X_fault_scaled = scaler.transform(X_fault_mts)\n",
        "\n",
        "    return X_scaled, X_fault_scaled, scaler\n",
        "\n",
        "\n",
        "def create_windows(data, window_size, prediction_length):\n",
        "    \"\"\"Slices the time series into sequences (windows).\"\"\"\n",
        "    windows = []\n",
        "    # Data must be at least window_size long\n",
        "    total_len = len(data) - window_size + 1\n",
        "\n",
        "    # Using reconstruction setup (Input == Target) for a true TranAD-like model\n",
        "    for i in range(total_len):\n",
        "        input_seq = data[i : i + window_size]\n",
        "        # Target sequence is the input sequence for reconstruction\n",
        "        target_seq = data[i : i + window_size]\n",
        "        windows.append((input_seq, target_seq))\n",
        "\n",
        "    # Stack the lists into numpy arrays\n",
        "    X_win = np.array([w[0] for w in windows], dtype=np.float32)\n",
        "    Y_win = np.array([w[1] for w in windows], dtype=np.float32)\n",
        "\n",
        "    print(f\"Created {len(X_win)} windows of size {window_size}.\")\n",
        "\n",
        "    return X_win, Y_win\n",
        "\n",
        "\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    \"\"\"A PyTorch Dataset for the time series windows.\"\"\"\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = torch.from_numpy(X).float()\n",
        "        self.Y = torch.from_numpy(Y).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Returns (input sequence, target sequence)\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "# --- 4. PYTORCH MODEL IMPLEMENTATION (Simplified TranAD Baseline) ---\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"Simple sinusoidal positional encoding.\"\"\"\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        # Denominator for the scaling factor\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1) # Shape (Max_Len, 1, D_model)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (Sequence_Length, Batch_Size, D_model)\n",
        "        # Add positional encoding\n",
        "        return x + self.pe[:x.size(0), :]\n",
        "\n",
        "\n",
        "class TransformerAD(nn.Module):\n",
        "    \"\"\"\n",
        "    A Transformer Encoder model for time series reconstruction.\n",
        "    This serves as the TranAD baseline.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, n_heads, n_layers, dropout, window_size):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # 1. Positional Encoding\n",
        "        self.pos_encoder = PositionalEncoding(d_model, max_len=window_size)\n",
        "\n",
        "        # 2. Encoder Stack\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=n_heads,\n",
        "            dropout=dropout,\n",
        "            batch_first=False # Expects (L, B, D)\n",
        "        )\n",
        "        # [Image of Transformer Encoder-Decoder Architecture]\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
        "\n",
        "        # 3. Decoder Head (Linear layer for reconstruction)\n",
        "        self.decoder = nn.Linear(d_model, d_model)\n",
        "\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src shape: (Batch_Size, Sequence_Length, D_model) -> (B, L, D)\n",
        "\n",
        "        # Transpose to (Sequence_Length, Batch_Size, D_model) -> (L, B, D)\n",
        "        src = src.permute(1, 0, 2)\n",
        "\n",
        "        # Add positional encoding\n",
        "        src = self.pos_encoder(src)\n",
        "\n",
        "        # Encode (L, B, D) -> (L, B, D)\n",
        "        memory = self.transformer_encoder(src)\n",
        "\n",
        "        # Decode (reconstruction) - apply linear layer element-wise\n",
        "        output = self.decoder(memory)\n",
        "\n",
        "        # Reshape back to (Batch_Size, Sequence_Length, D_model) -> (B, L, D)\n",
        "        output = output.permute(1, 0, 2)\n",
        "\n",
        "        # Output is the reconstructed input sequence\n",
        "        return output\n",
        "\n",
        "# --- 5. TRAINING AND EVALUATION FUNCTIONS ---\n",
        "\n",
        "def train_model(model, dataloader, criterion, optimizer, device, n_epochs):\n",
        "    \"\"\"Trains the model on normal data.\"\"\"\n",
        "    model.train()\n",
        "    print(f\"Training on device: {device}\")\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        total_loss = 0\n",
        "        for batch_x, batch_y in dataloader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            reconstruction = model(batch_x)\n",
        "\n",
        "            loss = criterion(reconstruction, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        print(f\"Epoch {epoch}/{n_epochs}, Loss: {avg_loss:.6f}\")\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "\n",
        "def evaluate_missing_modalities(model, X_normal_test, X_fault_test, window_size, missing_modalities_count, device):\n",
        "    \"\"\"\n",
        "    Performs the crucial missing modality test for the paper.\n",
        "    Calculates reconstruction error on the full 14-D vector.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # 1. Create windowed test data\n",
        "    X_normal_win, Y_normal_win = create_windows(X_normal_test, window_size, PREDICTION_LENGTH)\n",
        "    X_fault_win, Y_fault_win = create_windows(X_fault_test, window_size, PREDICTION_LENGTH)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for name, X_win, Y_win in [('Normal', X_normal_win, Y_normal_win), ('Fault', X_fault_win, Y_fault_win)]:\n",
        "\n",
        "            # Convert to PyTorch tensor\n",
        "            X_tensor = torch.from_numpy(X_win).float().to(device)\n",
        "            Y_tensor = torch.from_numpy(Y_win).float().to(device) # Original Ground Truth\n",
        "\n",
        "            # --- Full Modality Test (Baseline) ---\n",
        "            reconstruction_full = model(X_tensor)\n",
        "            error_full = torch.mean((reconstruction_full - Y_tensor)**2).item()\n",
        "            results[f'{name} - Full Modalities (MSE)'] = error_full\n",
        "\n",
        "            # --- Missing Modality Test (Core Paper Comparison) ---\n",
        "            X_missing = X_tensor.clone()\n",
        "\n",
        "            # Zero out the first 'missing_modalities_count' features in the input sequence\n",
        "            X_missing[:, :, :missing_modalities_count] = 0.0\n",
        "\n",
        "            reconstruction_missing = model(X_missing)\n",
        "\n",
        "            # Calculate error against the *original* ground truth (Y_tensor)\n",
        "            error_missing = torch.mean((reconstruction_missing - Y_tensor)**2).item()\n",
        "            results[f'{name} - Missing {missing_modalities_count} Modalities (MSE)'] = error_missing\n",
        "\n",
        "    print(\"\\n--- ANOMALY DETECTION TEST RESULTS (Reconstruction Error) ---\")\n",
        "    for key, val in results.items():\n",
        "        print(f\"{key}: {val:.6f}\")\n",
        "\n",
        "\n",
        "# --- 6. EXECUTION ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Detect device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # 1. Load and prepare data (MTS)\n",
        "    X_scaled_mts, X_fault_scaled_mts, scaler = None, None, None\n",
        "    try:\n",
        "        X_scaled_mts, X_fault_scaled_mts, scaler = load_and_preprocess_data(SYSTEM, RAW_DATA_DIR)\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Skipping model execution due to data loading failure: {e}\")\n",
        "        exit() # Exit the script if data failed to load/create\n",
        "    except Exception as e:\n",
        "        print(f\"An unknown error occurred during data loading: {e}\")\n",
        "        exit()\n",
        "\n",
        "    # Simple split of normal data into training (first 80%) and testing (last 20%)\n",
        "    split_idx = int(len(X_scaled_mts) * 0.8)\n",
        "    X_train_mts = X_scaled_mts[:split_idx]\n",
        "    X_normal_test_mts = X_scaled_mts[split_idx:]\n",
        "    X_normal_test_mts = X_normal_test_mts[:18999]\n",
        "    X_fault_scaled_mts = X_fault_scaled_mts[:999]\n",
        "\n",
        "    # 2. Create windowed datasets\n",
        "    X_train_win, Y_train_win = create_windows(X_train_mts, WINDOW_SIZE, PREDICTION_LENGTH)\n",
        "\n",
        "    # Create the PyTorch DataLoader\n",
        "    train_dataset = TimeSeriesDataset(X_train_win, Y_train_win)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    # 3. Initialize Model, Loss, and Optimizer\n",
        "    model = TransformerAD(D_MODEL, N_HEADS, N_LAYERS, DROPOUT, WINDOW_SIZE).to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    # 4. Train the model\n",
        "    start_time = time.time()\n",
        "    train_model(model, train_dataloader, criterion, optimizer, device, N_EPOCHS)\n",
        "    end_time = time.time()\n",
        "    print(f\"Total training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "    # 5. Run the core experiment: Evaluate Missing Modalities\n",
        "    evaluate_missing_modalities(\n",
        "        model,\n",
        "        X_normal_test_mts,\n",
        "        X_fault_scaled_mts,\n",
        "        WINDOW_SIZE,\n",
        "        missing_modalities_count=1,\n",
        "        device=device\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dYwiKyeBVrkI",
        "outputId": "75dd20e8-ed76-4c79-f876-bd836ff7b851"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully.\n",
            "Using device: cuda\n",
            "Loading data for system: RFQ\n",
            "Real data loaded successfully.\n",
            "Normal Data Pulses: 690, Fault Data Pulses: 182\n",
            "Concatenated and Scaled MTS shape: (3105000, 14)\n",
            "Created 2483901 windows of size 100.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on device: cuda\n",
            "Epoch 1/20, Loss: 0.021878\n",
            "Epoch 2/20, Loss: 0.007531\n",
            "Epoch 3/20, Loss: 0.006641\n",
            "Epoch 4/20, Loss: 0.006204\n",
            "Epoch 5/20, Loss: 0.005915\n",
            "Epoch 6/20, Loss: 0.005709\n",
            "Epoch 7/20, Loss: 0.005549\n",
            "Epoch 8/20, Loss: 0.005419\n",
            "Epoch 9/20, Loss: 0.005302\n",
            "Epoch 10/20, Loss: 0.005204\n",
            "Epoch 11/20, Loss: 0.005131\n",
            "Epoch 12/20, Loss: 0.005079\n",
            "Epoch 13/20, Loss: 0.005042\n",
            "Epoch 14/20, Loss: 0.005012\n",
            "Epoch 15/20, Loss: 0.004988\n",
            "Epoch 16/20, Loss: 0.004969\n",
            "Epoch 17/20, Loss: 0.004952\n",
            "Epoch 18/20, Loss: 0.004940\n",
            "Epoch 19/20, Loss: 0.004927\n",
            "Epoch 20/20, Loss: 0.004916\n",
            "Training complete.\n",
            "Total training time: 11506.68 seconds\n",
            "Created 18900 windows of size 100.\n",
            "Created 900 windows of size 100.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 14.42 GiB. GPU 0 has a total capacity of 14.74 GiB of which 13.96 GiB is free. Process 23215 has 798.00 MiB memory in use. Of the allocated memory 422.88 MiB is allocated by PyTorch, and 241.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-365334712.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;31m# 5. Run the core experiment: Evaluate Missing Modalities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m     evaluate_missing_modalities(\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mX_normal_test_mts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-365334712.py\u001b[0m in \u001b[0;36mevaluate_missing_modalities\u001b[0;34m(model, X_normal_test, X_fault_test, window_size, missing_modalities_count, device)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;31m# --- Full Modality Test (Baseline) ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0mreconstruction_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0merror_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstruction_full\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{name} - Full Modalities (MSE)'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_full\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-365334712.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;31m# Encode (L, B, D) -> (L, B, D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;31m# Decode (reconstruction) - apply linear layer element-wise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m             output = mod(\n\u001b[0m\u001b[1;32m    525\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    935\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_causal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             )\n\u001b[0;32m--> 937\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_ff_block\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# feed forward block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mRuns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 14.42 GiB. GPU 0 has a total capacity of 14.74 GiB of which 13.96 GiB is free. Process 23215 has 798.00 MiB memory in use. Of the allocated memory 422.88 MiB is allocated by PyTorch, and 241.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "def evaluate_missing_modalities(model, X_normal_test, X_fault_test, window_size, missing_modalities_count, batch_size, device):\n",
        "    \"\"\"\n",
        "    MODIFIED: Performs the core evaluation and collects the reconstruction error\n",
        "    (anomaly score) for *each window* to enable AUC calculation.\n",
        "\n",
        "    Returns: Tuple of (normal_full_scores, fault_full_scores, normal_missing_scores, fault_missing_scores)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    normal_full_scores = []\n",
        "    fault_full_scores = []\n",
        "    normal_missing_scores = []\n",
        "    fault_missing_scores = []\n",
        "\n",
        "    print(\"\\nStarting evaluation of missing modalities...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for name, X_mts in [('Normal', X_normal_test), ('Fault', X_fault_test)]:\n",
        "\n",
        "            X_win, Y_win = create_windows(X_mts, window_size, PREDICTION_LENGTH)\n",
        "\n",
        "            # Guard against insufficient data for windows\n",
        "            if len(X_win) == 0:\n",
        "                print(f\"Warning: Not enough {name} data ({len(X_mts)} steps) to create windows of size {window_size}. Skipping evaluation.\")\n",
        "                continue\n",
        "\n",
        "            test_dataset = TimeSeriesDataset(X_win, Y_win)\n",
        "            # Use batch_size for batched evaluation\n",
        "            test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "            current_scores_full = []\n",
        "            current_scores_missing = []\n",
        "\n",
        "            for batch_x, batch_y in test_dataloader:\n",
        "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "                # --- Full Modality Test ---\n",
        "                reconstruction_full = model(batch_x)\n",
        "                # Calculate MSE per window (B, L, D) -> (B)\n",
        "                # Anomaly Score = Mean Squared Error across the window sequence and all features\n",
        "                errors_batch_full = torch.mean((reconstruction_full - batch_y)**2, dim=(1, 2))\n",
        "                current_scores_full.extend(errors_batch_full.cpu().numpy())\n",
        "\n",
        "                # --- Missing Modality Test ---\n",
        "                X_missing = batch_x.clone()\n",
        "                # Mask the first 'missing_modalities_count' features\n",
        "                X_missing[:, :, :missing_modalities_count] = 0.0\n",
        "\n",
        "                reconstruction_missing = model(X_missing)\n",
        "\n",
        "                # Calculate MSE per window against the *original* target (Y_tensor)\n",
        "                errors_batch_missing = torch.mean((reconstruction_missing - batch_y)**2, dim=(1, 2))\n",
        "                current_scores_missing.extend(errors_batch_missing.cpu().numpy())\n",
        "\n",
        "            if name == 'Normal':\n",
        "                normal_full_scores = np.array(current_scores_full)\n",
        "                normal_missing_scores = np.array(current_scores_missing)\n",
        "            else: # 'Fault'\n",
        "                fault_full_scores = np.array(current_scores_full)\n",
        "                fault_missing_scores = np.array(current_scores_missing)\n",
        "\n",
        "            print(f\"Finished processing {name} data. {len(X_win)} windows evaluated.\")\n",
        "\n",
        "    return normal_full_scores, fault_full_scores, normal_missing_scores, fault_missing_scores\n",
        "\n",
        "\n",
        "def calculate_youden_auc(normal_scores, fault_scores, description):\n",
        "    \"\"\"\n",
        "    Calculates AUC-ROC and finds the optimal threshold using Youden's J statistic.\n",
        "    \"\"\"\n",
        "    if len(normal_scores) == 0 or len(fault_scores) == 0:\n",
        "        print(f\"\\n--- SKIPPING METRICS FOR {description} ---\")\n",
        "        print(\"Not enough normal or fault windows were created/found to calculate ROC/AUC. Please check your data or WINDOW_SIZE.\")\n",
        "        return\n",
        "\n",
        "    # 1. Prepare data (scores and true labels)\n",
        "    all_scores = np.concatenate([normal_scores, fault_scores])\n",
        "    # True labels: 0 for normal, 1 for fault/anomaly\n",
        "    true_labels = np.concatenate([np.zeros_like(normal_scores), np.ones_like(fault_scores)])\n",
        "\n",
        "    # Check for binary classification requirement\n",
        "    if len(np.unique(true_labels)) < 2:\n",
        "        print(f\"\\n--- SKIPPING METRICS FOR {description} ---\")\n",
        "        print(\"Only one class (all normal or all fault) was found in the test set. Cannot calculate AUC.\")\n",
        "        return\n",
        "\n",
        "    # 2. Calculate ROC curve metrics\n",
        "    # fpr = False Positive Rate, tpr = True Positive Rate\n",
        "    fpr, tpr, thresholds = roc_curve(true_labels, all_scores)\n",
        "\n",
        "    # 3. Calculate AUC\n",
        "    auc_score = roc_auc_score(true_labels, all_scores)\n",
        "\n",
        "    # 4. Calculate Youden's J for optimal threshold\n",
        "    # J = max(Sensitivity + Specificity - 1) = max(TPR + (1 - FPR) - 1) = max(TPR - FPR)\n",
        "    youden_j = tpr - fpr\n",
        "    optimal_idx = np.argmax(youden_j)\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "    # 5. Calculate final classification metrics using the optimal threshold\n",
        "    predicted_labels = (all_scores >= optimal_threshold).astype(int)\n",
        "\n",
        "    # Confusion Matrix components\n",
        "    TP = np.sum((true_labels == 1) & (predicted_labels == 1))\n",
        "    TN = np.sum((true_labels == 0) & (predicted_labels == 0))\n",
        "    FP = np.sum((true_labels == 0) & (predicted_labels == 1))\n",
        "    FN = np.sum((true_labels == 1) & (predicted_labels == 0))\n",
        "\n",
        "    # Calculate key metrics\n",
        "    sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "    accuracy = (TP + TN) / len(true_labels) if len(true_labels) > 0 else 0\n",
        "\n",
        "    print(f\"\\n--- CLASSIFICATION METRICS: {description} ---\")\n",
        "    print(f\"AUC-ROC Score: {auc_score:.4f}\")\n",
        "    print(f\"Optimal Threshold (Youden's J): {optimal_threshold:.6f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Sensitivity (TPR): {sensitivity:.4f}\")\n",
        "    print(f\"Specificity (TNR): {specificity:.4f}\")\n",
        "    print(f\"Youden's J Max Value: {youden_j[optimal_idx]:.4f}\")\n",
        "    # [Image of ROC Curve and Optimal Threshold]\n"
      ],
      "metadata": {
        "id": "CdbtKSQSkLnf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_full_scores, fault_full_scores, normal_missing_scores, fault_missing_scores = evaluate_missing_modalities(\n",
        "        model,\n",
        "        X_normal_test_mts,\n",
        "        X_fault_scaled_mts,\n",
        "        WINDOW_SIZE,\n",
        "        missing_modalities_count=1,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        device=device\n",
        "    )\n",
        "missing_modalities_count = 1\n",
        "    # 6. Calculate AUC and Youden's J for both scenarios\n",
        "calculate_youden_auc(normal_full_scores, fault_full_scores, \"Full Modalities Test\")\n",
        "calculate_youden_auc(normal_missing_scores, fault_missing_scores, f\"Missing {missing_modalities_count} Modalities Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly82yJpRGtew",
        "outputId": "603d81db-b900-4b25-fbda-ec51c3b85f4f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting evaluation of missing modalities...\n",
            "Created 18900 windows of size 100.\n",
            "Finished processing Normal data. 18900 windows evaluated.\n",
            "Created 900 windows of size 100.\n",
            "Finished processing Fault data. 900 windows evaluated.\n",
            "\n",
            "--- CLASSIFICATION METRICS: Full Modalities Test ---\n",
            "AUC-ROC Score: 1.0000\n",
            "Optimal Threshold (Youden's J): 0.064035\n",
            "Accuracy: 1.0000\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 1.0000\n",
            "Youden's J Max Value: 1.0000\n",
            "\n",
            "--- CLASSIFICATION METRICS: Missing 1 Modalities Test ---\n",
            "AUC-ROC Score: 1.0000\n",
            "Optimal Threshold (Youden's J): 0.063716\n",
            "Accuracy: 1.0000\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 1.0000\n",
            "Youden's J Max Value: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal_full_scores, fault_full_scores, normal_missing_scores, fault_missing_scores = evaluate_missing_modalities(\n",
        "        model,\n",
        "        X_normal_test_mts,\n",
        "        X_fault_scaled_mts,\n",
        "        WINDOW_SIZE,\n",
        "        missing_modalities_count=2,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        device=device\n",
        "    )\n",
        "missing_modalities_count = 2\n",
        "    # 6. Calculate AUC and Youden's J for both scenarios\n",
        "calculate_youden_auc(normal_full_scores, fault_full_scores, \"Full Modalities Test\")\n",
        "calculate_youden_auc(normal_missing_scores, fault_missing_scores, f\"Missing {missing_modalities_count} Modalities Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1ddXvURceHx",
        "outputId": "218e6278-e5a2-4459-d05d-d8dc85b6f45c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting evaluation of missing modalities...\n",
            "Created 18900 windows of size 100.\n",
            "Finished processing Normal data. 18900 windows evaluated.\n",
            "Created 900 windows of size 100.\n",
            "Finished processing Fault data. 900 windows evaluated.\n",
            "\n",
            "--- CLASSIFICATION METRICS: Full Modalities Test ---\n",
            "AUC-ROC Score: 1.0000\n",
            "Optimal Threshold (Youden's J): 0.064035\n",
            "Accuracy: 1.0000\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 1.0000\n",
            "Youden's J Max Value: 1.0000\n",
            "\n",
            "--- CLASSIFICATION METRICS: Missing 2 Modalities Test ---\n",
            "AUC-ROC Score: 0.9663\n",
            "Optimal Threshold (Youden's J): 0.068509\n",
            "Accuracy: 0.9667\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.9651\n",
            "Youden's J Max Value: 0.9651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal_full_scores, fault_full_scores, normal_missing_scores, fault_missing_scores = evaluate_missing_modalities(\n",
        "        model,\n",
        "        X_normal_test_mts,\n",
        "        X_fault_scaled_mts,\n",
        "        WINDOW_SIZE,\n",
        "        missing_modalities_count=3,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        device=device\n",
        "    )\n",
        "missing_modalities_count = 3\n",
        "    # 6. Calculate AUC and Youden's J for both scenarios\n",
        "calculate_youden_auc(normal_full_scores, fault_full_scores, \"Full Modalities Test\")\n",
        "calculate_youden_auc(normal_missing_scores, fault_missing_scores, f\"Missing {missing_modalities_count} Modalities Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4kHx0egcgzv",
        "outputId": "392608fd-fdb6-4038-8e19-b399ae7da685"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting evaluation of missing modalities...\n",
            "Created 18900 windows of size 100.\n",
            "Finished processing Normal data. 18900 windows evaluated.\n",
            "Created 900 windows of size 100.\n",
            "Finished processing Fault data. 900 windows evaluated.\n",
            "\n",
            "--- CLASSIFICATION METRICS: Full Modalities Test ---\n",
            "AUC-ROC Score: 1.0000\n",
            "Optimal Threshold (Youden's J): 0.064035\n",
            "Accuracy: 1.0000\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 1.0000\n",
            "Youden's J Max Value: 1.0000\n",
            "\n",
            "--- CLASSIFICATION METRICS: Missing 3 Modalities Test ---\n",
            "AUC-ROC Score: 0.9204\n",
            "Optimal Threshold (Youden's J): 0.068483\n",
            "Accuracy: 0.9222\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.9185\n",
            "Youden's J Max Value: 0.9185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal_full_scores, fault_full_scores, normal_missing_scores, fault_missing_scores = evaluate_missing_modalities(\n",
        "        model,\n",
        "        X_normal_test_mts,\n",
        "        X_fault_scaled_mts,\n",
        "        WINDOW_SIZE,\n",
        "        missing_modalities_count=4,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        device=device\n",
        "    )\n",
        "missing_modalities_count = 4\n",
        "    # 6. Calculate AUC and Youden's J for both scenarios\n",
        "calculate_youden_auc(normal_full_scores, fault_full_scores, \"Full Modalities Test\")\n",
        "calculate_youden_auc(normal_missing_scores, fault_missing_scores, f\"Missing {missing_modalities_count} Modalities Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA4_mQIYci2C",
        "outputId": "7a160f05-10cb-4137-bec4-4350f7864534"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting evaluation of missing modalities...\n",
            "Created 18900 windows of size 100.\n",
            "Finished processing Normal data. 18900 windows evaluated.\n",
            "Created 900 windows of size 100.\n",
            "Finished processing Fault data. 900 windows evaluated.\n",
            "\n",
            "--- CLASSIFICATION METRICS: Full Modalities Test ---\n",
            "AUC-ROC Score: 1.0000\n",
            "Optimal Threshold (Youden's J): 0.064035\n",
            "Accuracy: 1.0000\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 1.0000\n",
            "Youden's J Max Value: 1.0000\n",
            "\n",
            "--- CLASSIFICATION METRICS: Missing 4 Modalities Test ---\n",
            "AUC-ROC Score: 0.5110\n",
            "Optimal Threshold (Youden's J): 0.061030\n",
            "Accuracy: 0.5319\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.5096\n",
            "Youden's J Max Value: 0.5096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal_full_scores, fault_full_scores, normal_missing_scores, fault_missing_scores = evaluate_missing_modalities(\n",
        "        model,\n",
        "        X_normal_test_mts,\n",
        "        X_fault_scaled_mts,\n",
        "        WINDOW_SIZE,\n",
        "        missing_modalities_count=5,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        device=device\n",
        "    )\n",
        "missing_modalities_count = 5\n",
        "    # 6. Calculate AUC and Youden's J for both scenarios\n",
        "calculate_youden_auc(normal_full_scores, fault_full_scores, \"Full Modalities Test\")\n",
        "calculate_youden_auc(normal_missing_scores, fault_missing_scores, f\"Missing {missing_modalities_count} Modalities Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxcxzb7Nck28",
        "outputId": "60b650df-0b82-430e-fcd5-d97e015b8dde"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting evaluation of missing modalities...\n",
            "Created 18900 windows of size 100.\n",
            "Finished processing Normal data. 18900 windows evaluated.\n",
            "Created 900 windows of size 100.\n",
            "Finished processing Fault data. 900 windows evaluated.\n",
            "\n",
            "--- CLASSIFICATION METRICS: Full Modalities Test ---\n",
            "AUC-ROC Score: 1.0000\n",
            "Optimal Threshold (Youden's J): 0.064035\n",
            "Accuracy: 1.0000\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 1.0000\n",
            "Youden's J Max Value: 1.0000\n",
            "\n",
            "--- CLASSIFICATION METRICS: Missing 5 Modalities Test ---\n",
            "AUC-ROC Score: 0.3032\n",
            "Optimal Threshold (Youden's J): 0.060565\n",
            "Accuracy: 0.3346\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.3030\n",
            "Youden's J Max Value: 0.3030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal_full_scores, fault_full_scores, normal_missing_scores, fault_missing_scores = evaluate_missing_modalities(\n",
        "        model,\n",
        "        X_normal_test_mts,\n",
        "        X_fault_scaled_mts,\n",
        "        WINDOW_SIZE,\n",
        "        missing_modalities_count=6,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        device=device\n",
        "    )\n",
        "missing_modalities_count = 6\n",
        "    # 6. Calculate AUC and Youden's J for both scenarios\n",
        "calculate_youden_auc(normal_full_scores, fault_full_scores, \"Full Modalities Test\")\n",
        "calculate_youden_auc(normal_missing_scores, fault_missing_scores, f\"Missing {missing_modalities_count} Modalities Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Nq2LTr1fcl-",
        "outputId": "960bb7d2-f467-41c4-b534-f87854cc3298"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting evaluation of missing modalities...\n",
            "Created 18900 windows of size 100.\n",
            "Finished processing Normal data. 18900 windows evaluated.\n",
            "Created 900 windows of size 100.\n",
            "Finished processing Fault data. 900 windows evaluated.\n",
            "\n",
            "--- CLASSIFICATION METRICS: Full Modalities Test ---\n",
            "AUC-ROC Score: 1.0000\n",
            "Optimal Threshold (Youden's J): 0.064035\n",
            "Accuracy: 1.0000\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 1.0000\n",
            "Youden's J Max Value: 1.0000\n",
            "\n",
            "--- CLASSIFICATION METRICS: Missing 6 Modalities Test ---\n",
            "AUC-ROC Score: 0.2891\n",
            "Optimal Threshold (Youden's J): 0.064937\n",
            "Accuracy: 0.3211\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.2888\n",
            "Youden's J Max Value: 0.2888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal_full_scores, fault_full_scores, normal_missing_scores, fault_missing_scores = evaluate_missing_modalities(\n",
        "        model,\n",
        "        X_normal_test_mts,\n",
        "        X_fault_scaled_mts,\n",
        "        WINDOW_SIZE,\n",
        "        missing_modalities_count=7,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        device=device\n",
        "    )\n",
        "missing_modalities_count = 7\n",
        "    # 6. Calculate AUC and Youden's J for both scenarios\n",
        "calculate_youden_auc(normal_full_scores, fault_full_scores, \"Full Modalities Test\")\n",
        "calculate_youden_auc(normal_missing_scores, fault_missing_scores, f\"Missing {missing_modalities_count} Modalities Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca-vXuhwfgfv",
        "outputId": "e3e43241-6f6b-4cd8-c21d-1ac6b0375227"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting evaluation of missing modalities...\n",
            "Created 18900 windows of size 100.\n",
            "Finished processing Normal data. 18900 windows evaluated.\n",
            "Created 900 windows of size 100.\n",
            "Finished processing Fault data. 900 windows evaluated.\n",
            "\n",
            "--- CLASSIFICATION METRICS: Full Modalities Test ---\n",
            "AUC-ROC Score: 1.0000\n",
            "Optimal Threshold (Youden's J): 0.064035\n",
            "Accuracy: 1.0000\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 1.0000\n",
            "Youden's J Max Value: 1.0000\n",
            "\n",
            "--- CLASSIFICATION METRICS: Missing 7 Modalities Test ---\n",
            "AUC-ROC Score: 0.1877\n",
            "Optimal Threshold (Youden's J): 0.069901\n",
            "Accuracy: 0.2244\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.1875\n",
            "Youden's J Max Value: 0.1875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal_full_scores, fault_full_scores, normal_missing_scores, fault_missing_scores = evaluate_missing_modalities(\n",
        "        model,\n",
        "        X_normal_test_mts,\n",
        "        X_fault_scaled_mts,\n",
        "        WINDOW_SIZE,\n",
        "        missing_modalities_count=8,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        device=device\n",
        "    )\n",
        "missing_modalities_count = 8\n",
        "    # 6. Calculate AUC and Youden's J for both scenarios\n",
        "calculate_youden_auc(normal_full_scores, fault_full_scores, \"Full Modalities Test\")\n",
        "calculate_youden_auc(normal_missing_scores, fault_missing_scores, f\"Missing {missing_modalities_count} Modalities Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgckDVDyfmS_",
        "outputId": "aaae5c9f-015e-4ab1-888d-d30784038a8c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting evaluation of missing modalities...\n",
            "Created 18900 windows of size 100.\n",
            "Finished processing Normal data. 18900 windows evaluated.\n",
            "Created 900 windows of size 100.\n",
            "Finished processing Fault data. 900 windows evaluated.\n",
            "\n",
            "--- CLASSIFICATION METRICS: Full Modalities Test ---\n",
            "AUC-ROC Score: 1.0000\n",
            "Optimal Threshold (Youden's J): 0.064035\n",
            "Accuracy: 1.0000\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 1.0000\n",
            "Youden's J Max Value: 1.0000\n",
            "\n",
            "--- CLASSIFICATION METRICS: Missing 8 Modalities Test ---\n",
            "AUC-ROC Score: 0.1839\n",
            "Optimal Threshold (Youden's J): 0.070760\n",
            "Accuracy: 0.2209\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.1838\n",
            "Youden's J Max Value: 0.1838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal_full_scores, fault_full_scores, normal_missing_scores, fault_missing_scores = evaluate_missing_modalities(\n",
        "        model,\n",
        "        X_normal_test_mts,\n",
        "        X_fault_scaled_mts,\n",
        "        WINDOW_SIZE,\n",
        "        missing_modalities_count=9,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        device=device\n",
        "    )\n",
        "missing_modalities_count = 9\n",
        "    # 6. Calculate AUC and Youden's J for both scenarios\n",
        "calculate_youden_auc(normal_full_scores, fault_full_scores, \"Full Modalities Test\")\n",
        "calculate_youden_auc(normal_missing_scores, fault_missing_scores, f\"Missing {missing_modalities_count} Modalities Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adzAklNofp4J",
        "outputId": "5479177e-e326-471e-f18f-1fb78b3d62b8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting evaluation of missing modalities...\n",
            "Created 18900 windows of size 100.\n",
            "Finished processing Normal data. 18900 windows evaluated.\n",
            "Created 900 windows of size 100.\n",
            "Finished processing Fault data. 900 windows evaluated.\n",
            "\n",
            "--- CLASSIFICATION METRICS: Full Modalities Test ---\n",
            "AUC-ROC Score: 1.0000\n",
            "Optimal Threshold (Youden's J): 0.064035\n",
            "Accuracy: 1.0000\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 1.0000\n",
            "Youden's J Max Value: 1.0000\n",
            "\n",
            "--- CLASSIFICATION METRICS: Missing 9 Modalities Test ---\n",
            "AUC-ROC Score: 0.0917\n",
            "Optimal Threshold (Youden's J): 0.067269\n",
            "Accuracy: 0.1326\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.0913\n",
            "Youden's J Max Value: 0.0913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal_full_scores, fault_full_scores, normal_missing_scores, fault_missing_scores = evaluate_missing_modalities(\n",
        "        model,\n",
        "        X_normal_test_mts,\n",
        "        X_fault_scaled_mts,\n",
        "        WINDOW_SIZE,\n",
        "        missing_modalities_count=10,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        device=device\n",
        "    )\n",
        "missing_modalities_count = 10\n",
        "    # 6. Calculate AUC and Youden's J for both scenarios\n",
        "calculate_youden_auc(normal_full_scores, fault_full_scores, \"Full Modalities Test\")\n",
        "calculate_youden_auc(normal_missing_scores, fault_missing_scores, f\"Missing {missing_modalities_count} Modalities Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEaW2jkef2aj",
        "outputId": "b92ad819-2259-4b62-cf8e-0648811cd1b9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting evaluation of missing modalities...\n",
            "Created 18900 windows of size 100.\n",
            "Finished processing Normal data. 18900 windows evaluated.\n",
            "Created 900 windows of size 100.\n",
            "Finished processing Fault data. 900 windows evaluated.\n",
            "\n",
            "--- CLASSIFICATION METRICS: Full Modalities Test ---\n",
            "AUC-ROC Score: 1.0000\n",
            "Optimal Threshold (Youden's J): 0.064035\n",
            "Accuracy: 1.0000\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 1.0000\n",
            "Youden's J Max Value: 1.0000\n",
            "\n",
            "--- CLASSIFICATION METRICS: Missing 10 Modalities Test ---\n",
            "AUC-ROC Score: 0.0000\n",
            "Optimal Threshold (Youden's J): inf\n",
            "Accuracy: 0.9545\n",
            "Sensitivity (TPR): 0.0000\n",
            "Specificity (TNR): 1.0000\n",
            "Youden's J Max Value: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal_full_scores, fault_full_scores, normal_missing_scores, fault_missing_scores = evaluate_missing_modalities(\n",
        "        model,\n",
        "        X_normal_test_mts,\n",
        "        X_fault_scaled_mts,\n",
        "        WINDOW_SIZE,\n",
        "        missing_modalities_count=11,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        device=device\n",
        "    )\n",
        "missing_modalities_count = 11\n",
        "    # 6. Calculate AUC and Youden's J for both scenarios\n",
        "calculate_youden_auc(normal_full_scores, fault_full_scores, \"Full Modalities Test\")\n",
        "calculate_youden_auc(normal_missing_scores, fault_missing_scores, f\"Missing {missing_modalities_count} Modalities Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTmS5mWZf5H4",
        "outputId": "01c597ea-31e5-4e57-e2e0-b86fe98c2308"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting evaluation of missing modalities...\n",
            "Created 18900 windows of size 100.\n",
            "Finished processing Normal data. 18900 windows evaluated.\n",
            "Created 900 windows of size 100.\n",
            "Finished processing Fault data. 900 windows evaluated.\n",
            "\n",
            "--- CLASSIFICATION METRICS: Full Modalities Test ---\n",
            "AUC-ROC Score: 1.0000\n",
            "Optimal Threshold (Youden's J): 0.064035\n",
            "Accuracy: 1.0000\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 1.0000\n",
            "Youden's J Max Value: 1.0000\n",
            "\n",
            "--- CLASSIFICATION METRICS: Missing 11 Modalities Test ---\n",
            "AUC-ROC Score: 0.0000\n",
            "Optimal Threshold (Youden's J): inf\n",
            "Accuracy: 0.9545\n",
            "Sensitivity (TPR): 0.0000\n",
            "Specificity (TNR): 1.0000\n",
            "Youden's J Max Value: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal_full_scores, fault_full_scores, normal_missing_scores, fault_missing_scores = evaluate_missing_modalities(\n",
        "        model,\n",
        "        X_normal_test_mts,\n",
        "        X_fault_scaled_mts,\n",
        "        WINDOW_SIZE,\n",
        "        missing_modalities_count=12,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        device=device\n",
        "    )\n",
        "missing_modalities_count = 12\n",
        "    # 6. Calculate AUC and Youden's J for both scenarios\n",
        "calculate_youden_auc(normal_full_scores, fault_full_scores, \"Full Modalities Test\")\n",
        "calculate_youden_auc(normal_missing_scores, fault_missing_scores, f\"Missing {missing_modalities_count} Modalities Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2DzNHLqf9RF",
        "outputId": "643d3ad0-1aaf-4ab3-cc06-ceb6e5a9f118"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting evaluation of missing modalities...\n",
            "Created 18900 windows of size 100.\n",
            "Finished processing Normal data. 18900 windows evaluated.\n",
            "Created 900 windows of size 100.\n",
            "Finished processing Fault data. 900 windows evaluated.\n",
            "\n",
            "--- CLASSIFICATION METRICS: Full Modalities Test ---\n",
            "AUC-ROC Score: 1.0000\n",
            "Optimal Threshold (Youden's J): 0.064035\n",
            "Accuracy: 1.0000\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 1.0000\n",
            "Youden's J Max Value: 1.0000\n",
            "\n",
            "--- CLASSIFICATION METRICS: Missing 12 Modalities Test ---\n",
            "AUC-ROC Score: 0.0000\n",
            "Optimal Threshold (Youden's J): inf\n",
            "Accuracy: 0.9545\n",
            "Sensitivity (TPR): 0.0000\n",
            "Specificity (TNR): 1.0000\n",
            "Youden's J Max Value: 0.0000\n"
          ]
        }
      ]
    }
  ]
}