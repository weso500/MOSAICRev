{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOfZbdchwFPxfdmMmlyiI26",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weso500/MOSAICRev/blob/main/GANonmaly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time\n",
        "\n",
        "# --- Colab Setup: Run this cell first ---\n",
        "# NOTE: The pip install and mkdir commands are assumed to have been run successfully.\n",
        "# !pip install torch numpy pandas scikit-learn\n",
        "# !mkdir -p '/content/drive/MyDrive/Globecom Paper/For Jason/IOT-Anomaly-Detection/Raw_Data'\n",
        "\n",
        "# --- Step 1: Mount Google Drive (Essential for accessing files) ---\n",
        "try:\n",
        "    print(\"Mounting Google Drive...\")\n",
        "    # Using 'force_remount=True' is often necessary if the notebook has disconnected/reconnected\n",
        "    # drive.mount('/content/drive', force_remount=True)\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting Google Drive: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXpS0ZO2CbV8",
        "outputId": "97af8ae1-fa5e-4866-d324-4b9a6a5eb358"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Colab Setup: Run this cell first ---\n",
        "# This file implements the Ganomaly baseline using GRU layers for time-series anomaly detection.\n",
        "# It is designed to run in the same environment as the TranAD baseline.\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import torch.optim as optim\n",
        "\n",
        "# --- 2. CONFIGURATION (Matches TranAD Configuration) ---\n",
        "SYSTEM = 'RFQ'\n",
        "# IMPORTANT: Full Google Drive path for correct file access\n",
        "RAW_DATA_DIR = '/content/drive/MyDrive/Globecom Paper/For Jason/IOT-Anomaly-Detection/Raw_Data'\n",
        "WINDOW_SIZE = 100           # Sequence length (L)\n",
        "N_FEATURES = 14             # Dimension of the feature vector (D_model)\n",
        "PREDICTION_LENGTH = 1       # Target sequence length (1 for anomaly detection)\n",
        "N_EPOCHS = 30              # GANs often require more epochs to stabilize\n",
        "BATCH_SIZE = 512\n",
        "G_LR = 1e-4                 # Generator Learning Rate\n",
        "D_LR = 1e-4                 # Discriminator Learning Rate\n",
        "\n",
        "# Ganomaly Hyperparameters\n",
        "LATENT_DIM = 64             # Size of the latent space (Z)\n",
        "GRU_HIDDEN_SIZE = 128\n",
        "ALPHA = 1.0                 # Weight for Reconstruction Loss\n",
        "BETA = 0.1                  # Weight for Adversarial Loss (L_adv)\n",
        "GAMMA = 1.0                 # Weight for Encoder/Latent Loss (L_enc)\n",
        "\n",
        "# --- 3. DATA UTILITIES (Copied for self-contained execution) ---\n",
        "\n",
        "def load_and_preprocess_data(system, raw_data_dir):\n",
        "    \"\"\"Loads, splits, and preprocesses the accelerator data.\"\"\"\n",
        "    print(f\"Loading data for system: {system}\")\n",
        "    x_path = os.path.join(raw_data_dir, f'{system}.npy')\n",
        "    y_path = os.path.join(raw_data_dir, f'{system}_labels.npy')\n",
        "\n",
        "    X, Y = None, None\n",
        "\n",
        "    if not os.path.exists(x_path) or not os.path.exists(y_path):\n",
        "        print(f\"--- WARNING: Data files not found. Creating DUMMY DATA. ---\")\n",
        "        # Ensure DUMMY DATA shape matches expected N_FEATURES\n",
        "        X = np.random.rand(1000, 200, N_FEATURES)\n",
        "        Y = np.array([[i, 'Run', 'type'] for i in range(800)] +\n",
        "                     [[i + 800, 'Fault', 'type'] for i in range(200)], dtype=object)\n",
        "    else:\n",
        "        try:\n",
        "            X = np.load(x_path)\n",
        "            Y = np.load(y_path, allow_pickle=True)\n",
        "            print(\"Real data loaded successfully.\")\n",
        "        except ValueError as e:\n",
        "            print(f\"\\n--- ERROR HANDLING: Caught ValueError during loading: {e} ---\")\n",
        "            X = np.load(x_path, allow_pickle=True)\n",
        "            Y = np.load(y_path, allow_pickle=True)\n",
        "            print(\"Reload successful using allow_pickle=True.\")\n",
        "\n",
        "    if X is None or Y is None:\n",
        "        raise RuntimeError(\"Data failed to load or create dummy data.\")\n",
        "\n",
        "    # Data shape consistency check\n",
        "    if X.shape[-1] != N_FEATURES:\n",
        "        raise ValueError(f\"Data feature size mismatch: Expected {N_FEATURES}, but loaded data has {X.shape[-1]}. Check N_FEATURES config.\")\n",
        "\n",
        "    fault_indices, normal_indices = np.where(Y[:,1] == 'Fault')[0], np.where(Y[:,1] == 'Run')[0]\n",
        "    Xnormal = X[normal_indices, :, :]\n",
        "    Xfault = X[fault_indices, :, :]\n",
        "\n",
        "    print(f\"Normal Data Pulses: {len(Xnormal)}, Fault Data Pulses: {len(Xfault)}\")\n",
        "\n",
        "    n_pulses, n_times, n_features = Xnormal.shape\n",
        "    X_mts = Xnormal.reshape(-1, n_features)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X_mts)\n",
        "    print(f\"Concatenated and Scaled MTS shape: {X_scaled.shape}\")\n",
        "\n",
        "    X_fault_mts = Xfault.reshape(-1, n_features)\n",
        "    X_fault_scaled = scaler.transform(X_fault_mts)\n",
        "\n",
        "    return X_scaled, X_fault_scaled, scaler\n",
        "\n",
        "\n",
        "def create_windows(data, window_size, prediction_length):\n",
        "    \"\"\"Slices the time series into sequences (windows).\"\"\"\n",
        "    windows = []\n",
        "    # Calculate the total length of the time series\n",
        "    total_len = len(data) - window_size + 1\n",
        "\n",
        "    for i in range(total_len):\n",
        "        # Input and target are the same sequence for the autoencoder/GAN reconstruction\n",
        "        input_seq = data[i : i + window_size]\n",
        "        target_seq = data[i : i + window_size]\n",
        "        windows.append((input_seq, target_seq))\n",
        "\n",
        "    X_win = np.array([w[0] for w in windows], dtype=np.float32)\n",
        "    Y_win = np.array([w[1] for w in windows], dtype=np.float32)\n",
        "\n",
        "    print(f\"Created {len(X_win)} windows of size {window_size}.\")\n",
        "\n",
        "    return X_win, Y_win\n",
        "\n",
        "\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    \"\"\"A PyTorch Dataset for the time series windows.\"\"\"\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = torch.from_numpy(X).float()\n",
        "        self.Y = torch.from_numpy(Y).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Returns (input sequence, target sequence)\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "# --- 4. PYTORCH GANOMALY MODEL IMPLEMENTATION ---\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"Ganomaly Generator: Encoder -> Latent -> Decoder.\"\"\"\n",
        "    def __init__(self, input_size, hidden_size, latent_dim, seq_len):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "        # Encoder (GRU maps sequence to hidden state)\n",
        "        self.encoder = nn.GRU(input_size, hidden_size, batch_first=True)\n",
        "        # Hidden state to Latent Vector (Z_original)\n",
        "        self.to_latent = nn.Linear(hidden_size, latent_dim)\n",
        "        # Latent Vector back to Initial Hidden State for Decoder\n",
        "        self.from_latent = nn.Linear(latent_dim, hidden_size)\n",
        "\n",
        "        # Decoder (GRU maps hidden state to reconstructed sequence)\n",
        "        self.decoder = nn.GRU(input_size, hidden_size, batch_first=True)\n",
        "        # Hidden state to Output Feature\n",
        "        self.to_output = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (B, L, D)\n",
        "\n",
        "        # Encoder (Get final hidden state)\n",
        "        # Pass the whole sequence through the GRU\n",
        "        _, h_n_enc = self.encoder(x) # h_n_enc shape: (1, B, H)\n",
        "\n",
        "        # Latent Vector (Z_original)\n",
        "        z = self.to_latent(h_n_enc.squeeze(0)) # z shape: (B, Z)\n",
        "\n",
        "        # Decoder Initial Hidden State\n",
        "        h_n_dec = self.from_latent(z).unsqueeze(0) # h_n_dec shape: (1, B, H)\n",
        "\n",
        "        # Decoder Input\n",
        "        # For Autoencoder style reconstruction, the input sequence is passed again\n",
        "        x_dec = x\n",
        "\n",
        "        # Decoder\n",
        "        output_seq, _ = self.decoder(x_dec, h_n_dec) # output_seq shape: (B, L, H)\n",
        "\n",
        "        # Map hidden states to reconstructed data\n",
        "        reconstruction = self.to_output(output_seq) # reconstruction shape: (B, L, D)\n",
        "\n",
        "        # Return reconstruction (X_hat) and the latent vector (Z_original)\n",
        "        return reconstruction, z\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"Ganomaly Discriminator: Encoder -> Feature Map -> Classifier.\"\"\"\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "\n",
        "        # Feature Extractor (GRU maps sequence to hidden state/feature map)\n",
        "        self.extractor = nn.GRU(input_size, hidden_size, batch_first=True)\n",
        "\n",
        "        # Classifier (From hidden state to a single prediction [Real/Fake])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (B, L, D)\n",
        "        _, h_n = self.extractor(x) # h_n shape: (1, B, H)\n",
        "        feature_map = h_n.squeeze(0) # feature_map shape: (B, H)\n",
        "\n",
        "        # Classification: Real (1) or Fake (0)\n",
        "        classification = self.classifier(feature_map) # classification shape: (B, 1)\n",
        "\n",
        "        # Return classification score and the final hidden state (feature map)\n",
        "        return classification, feature_map\n",
        "\n",
        "\n",
        "class GanomalyModel(nn.Module):\n",
        "    \"\"\"Wrapper class for Ganomaly components.\"\"\"\n",
        "    def __init__(self, input_size, hidden_size, latent_dim, seq_len):\n",
        "        super().__init__()\n",
        "        self.G = Generator(input_size, hidden_size, latent_dim, seq_len)\n",
        "        self.D = Discriminator(input_size, hidden_size)\n",
        "\n",
        "        # In Ganomaly, a separate Encoder (E) is used to encode the reconstructed data (X_hat)\n",
        "        # into a reconstructed latent vector (Z_hat). We use the same architecture as G's encoder.\n",
        "        self.E = self._create_encoder(input_size, hidden_size, latent_dim)\n",
        "\n",
        "    def _create_encoder(self, input_size, hidden_size, latent_dim):\n",
        "        \"\"\"Creates a separate encoder for the reconstruction latent space.\"\"\"\n",
        "        # This setup must perfectly mirror the Encoder section of the Generator (G)\n",
        "        encoder_gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
        "        to_latent = nn.Linear(hidden_size, latent_dim)\n",
        "        return nn.Sequential(encoder_gru, to_latent)\n",
        "\n",
        "    def encode_reconstruction(self, x_hat):\n",
        "        # x_hat shape: (B, L, D)\n",
        "        # GRU maps sequence to hidden state\n",
        "        _, h_n = self.E[0](x_hat)\n",
        "        # Hidden state to Latent Vector (Z_hat)\n",
        "        z_hat = self.E[1](h_n.squeeze(0)) # z_hat shape: (B, Z)\n",
        "        return z_hat\n",
        "\n",
        "\n",
        "# --- 5. TRAINING AND EVALUATION FUNCTIONS ---\n",
        "\n",
        "def train_ganomaly(model, dataloader, device, n_epochs):\n",
        "    \"\"\"Trains the Ganomaly model.\"\"\"\n",
        "\n",
        "    model.train()\n",
        "    bce_criterion = nn.BCELoss()\n",
        "    mse_criterion = nn.MSELoss()\n",
        "\n",
        "    # Optimizers are now defined in main, but we use the global hyperparams\n",
        "    G_params = list(model.G.parameters()) + list(model.E.parameters())\n",
        "    optimizer_G = optim.Adam(G_params, lr=G_LR, betas=(0.5, 0.999))\n",
        "    optimizer_D = optim.Adam(model.D.parameters(), lr=D_LR, betas=(0.5, 0.999))\n",
        "\n",
        "    print(f\"\\nStarting Ganomaly Training on device: {device}\")\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        total_loss_G = 0\n",
        "        total_loss_D = 0\n",
        "\n",
        "        for batch_x, _ in dataloader:\n",
        "            batch_x = batch_x.to(device)\n",
        "            batch_size = batch_x.size(0)\n",
        "\n",
        "            # --- 1. Train Discriminator (D) ---\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            # D Loss on Real Data (Target: 1)\n",
        "            output_real, _ = model.D(batch_x)\n",
        "            labels_real = torch.full((batch_size, 1), 1.0, device=device)\n",
        "            loss_D_real = bce_criterion(output_real, labels_real)\n",
        "\n",
        "            # D Loss on Fake Data (Reconstruction from G, Target: 0)\n",
        "            reconstruction, _ = model.G(batch_x)\n",
        "            # D's input is the reconstruction, detached from G to avoid G gradients\n",
        "            output_fake, _ = model.D(reconstruction.detach())\n",
        "            labels_fake = torch.full((batch_size, 1), 0.0, device=device)\n",
        "            loss_D_fake = bce_criterion(output_fake, labels_fake)\n",
        "\n",
        "            loss_D = loss_D_real + loss_D_fake\n",
        "            loss_D.backward()\n",
        "            optimizer_D.step()\n",
        "            total_loss_D += loss_D.item()\n",
        "\n",
        "            # --- 2. Train Generator (G) and Encoder (E) ---\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            reconstruction, z_original = model.G(batch_x)\n",
        "\n",
        "            # L_rec: Reconstruction Loss (X_hat vs X)\n",
        "            loss_rec = mse_criterion(reconstruction, batch_x)\n",
        "\n",
        "            # L_adv: Adversarial Loss (G wants D to think X_hat is Real, Target: 1)\n",
        "            output_fake_for_G, fm_fake = model.D(reconstruction)\n",
        "            labels_real_for_G = torch.full((batch_size, 1), 1.0, device=device)\n",
        "            loss_adv = bce_criterion(output_fake_for_G, labels_real_for_G)\n",
        "\n",
        "            # L_enc: Encoder Loss (Latent consistency: Z_hat vs Z_original)\n",
        "            z_reconstructed = model.encode_reconstruction(reconstruction)\n",
        "            loss_enc = mse_criterion(z_reconstructed, z_original)\n",
        "\n",
        "            # Total Generator Loss (L_G)\n",
        "            loss_G = (ALPHA * loss_rec) + (BETA * loss_adv) + (GAMMA * loss_enc)\n",
        "\n",
        "            loss_G.backward()\n",
        "            optimizer_G.step()\n",
        "            total_loss_G += loss_G.item()\n",
        "\n",
        "        avg_loss_G = total_loss_G / len(dataloader)\n",
        "        avg_loss_D = total_loss_D / len(dataloader)\n",
        "\n",
        "        # Print update every 10 epochs for cleaner output\n",
        "        if (epoch % 10 == 0) or (epoch == n_epochs):\n",
        "            print(f\"Epoch {epoch:03d}/{n_epochs}, G Loss: {avg_loss_G:.6f}, D Loss: {avg_loss_D:.6f}\")\n",
        "\n",
        "    print(\"Ganomaly Training complete.\")\n",
        "\n",
        "\n",
        "def evaluate_ganomaly(model, X_normal_test_mts, X_fault_test_mts, window_size, missing_modalities_count, device):\n",
        "    \"\"\"\n",
        "    Calculates the Ganomaly score for both normal and fault test data under two conditions.\n",
        "    Anomaly Score = ALPHA * L_rec + GAMMA * L_enc\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    mse_criterion = nn.MSELoss(reduction='none')\n",
        "\n",
        "    normal_full_scores = []\n",
        "    fault_full_scores = []\n",
        "    normal_missing_scores = []\n",
        "    fault_missing_scores = []\n",
        "\n",
        "    print(\"\\nStarting Ganomaly Evaluation...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Iterate through Normal and Fault test data\n",
        "        for name, X_mts in [('Normal', X_normal_test_mts), ('Fault', X_fault_test_mts)]:\n",
        "\n",
        "            # Create windows on the MTS data\n",
        "            X_win_eval, Y_win_eval = create_windows(X_mts, window_size, PREDICTION_LENGTH)\n",
        "\n",
        "            if len(X_win_eval) == 0:\n",
        "                print(f\"Warning: No {name} test windows provided. Skipping evaluation.\")\n",
        "                continue\n",
        "\n",
        "            test_dataset = TimeSeriesDataset(X_win_eval, Y_win_eval)\n",
        "            test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "            current_scores_full = []\n",
        "            current_scores_missing = []\n",
        "\n",
        "            for batch_x, _ in test_dataloader:\n",
        "                batch_x = batch_x.to(device)\n",
        "\n",
        "                # --- Full Modality Test ---\n",
        "                reconstruction_full, z_original_full = model.G(batch_x)\n",
        "                z_reconstructed_full = model.encode_reconstruction(reconstruction_full)\n",
        "\n",
        "                # L_rec: MSE loss over the entire sequence, averaged per window\n",
        "                l_rec_full = mse_criterion(reconstruction_full, batch_x).mean(dim=(1, 2))\n",
        "                # L_enc: MSE loss in the latent space, averaged per window\n",
        "                l_enc_full = mse_criterion(z_reconstructed_full, z_original_full).mean(dim=1)\n",
        "\n",
        "                # Anomaly Score (Full)\n",
        "                score_full = (ALPHA * l_rec_full) + (GAMMA * l_enc_full)\n",
        "                current_scores_full.extend(score_full.cpu().numpy())\n",
        "\n",
        "                # --- Missing Modality Test ---\n",
        "                X_missing = batch_x.clone()\n",
        "                # Mask the first `missing_modalities_count` features to zero\n",
        "                X_missing[:, :, :missing_modalities_count] = 0.0\n",
        "\n",
        "                reconstruction_missing, z_original_missing = model.G(X_missing)\n",
        "                z_reconstructed_missing = model.encode_reconstruction(reconstruction_missing)\n",
        "\n",
        "                # L_rec: MSE loss between Reconstruction and the *Original Input (batch_x)*\n",
        "                l_rec_missing = mse_criterion(reconstruction_missing, batch_x).mean(dim=(1, 2))\n",
        "                # L_enc: MSE loss in the latent space\n",
        "                l_enc_missing = mse_criterion(z_reconstructed_missing, z_original_missing).mean(dim=1)\n",
        "\n",
        "                # Anomaly Score (Missing)\n",
        "                score_missing = (ALPHA * l_rec_missing) + (GAMMA * l_enc_missing)\n",
        "                current_scores_missing.extend(score_missing.cpu().numpy())\n",
        "\n",
        "            if name == 'Normal':\n",
        "                normal_full_scores.extend(current_scores_full)\n",
        "                normal_missing_scores.extend(current_scores_missing)\n",
        "            else: # 'Fault'\n",
        "                fault_full_scores.extend(current_scores_full)\n",
        "                fault_missing_scores.extend(current_scores_missing)\n",
        "\n",
        "            print(f\"Finished processing {len(X_win_eval)} {name} windows.\")\n",
        "\n",
        "    # Convert list to numpy array before returning\n",
        "    return (np.array(normal_full_scores), np.array(fault_full_scores),\n",
        "            np.array(normal_missing_scores), np.array(fault_missing_scores))\n",
        "\n",
        "\n",
        "def calculate_youden_auc(normal_scores, fault_scores, description):\n",
        "    \"\"\"Calculates AUC-ROC and finds the optimal threshold using Youden's J statistic.\"\"\"\n",
        "    if len(normal_scores) == 0 or len(fault_scores) == 0:\n",
        "        print(f\"\\n--- SKIPPING METRICS FOR {description} ---\")\n",
        "        print(\"Not enough normal or fault windows were created/found to calculate ROC/AUC.\")\n",
        "        return\n",
        "\n",
        "    all_scores = np.concatenate([normal_scores, fault_scores])\n",
        "    true_labels = np.concatenate([np.zeros_like(normal_scores), np.ones_like(fault_scores)])\n",
        "\n",
        "    if len(np.unique(true_labels)) < 2:\n",
        "        print(f\"\\n--- SKIPPING METRICS FOR {description} ---\")\n",
        "        print(\"Only one class (all normal or all fault) was found in the test set. Cannot calculate AUC.\")\n",
        "        return\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(true_labels, all_scores)\n",
        "    auc_score = roc_auc_score(true_labels, all_scores)\n",
        "\n",
        "    # Youden's J = Sensitivity + Specificity - 1 = TPR - FPR\n",
        "    youden_j = tpr - fpr\n",
        "    optimal_idx = np.argmax(youden_j)\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "    predicted_labels = (all_scores >= optimal_threshold).astype(int)\n",
        "\n",
        "    TP = np.sum((true_labels == 1) & (predicted_labels == 1))\n",
        "    TN = np.sum((true_labels == 0) & (predicted_labels == 0))\n",
        "    FP = np.sum((true_labels == 0) & (predicted_labels == 1))\n",
        "    FN = np.sum((true_labels == 1) & (predicted_labels == 0))\n",
        "\n",
        "    sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "    accuracy = (TP + TN) / len(true_labels) if len(true_labels) > 0 else 0\n",
        "\n",
        "    print(f\"\\n--- CLASSIFICATION METRICS: {description} ---\")\n",
        "    print(f\"AUC-ROC Score: {auc_score:.4f}\")\n",
        "    print(f\"Optimal Threshold (Youden's J): {optimal_threshold:.6f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Sensitivity (TPR): {sensitivity:.4f}\")\n",
        "    print(f\"Specificity (TNR): {specificity:.4f}\")\n",
        "    print(f\"Youden's J Max Value: {youden_j[optimal_idx]:.4f}\")\n",
        "\n",
        "\n",
        "# --- 6. EXECUTION ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Detect device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # 1. Load and prepare data (MTS)\n",
        "    X_scaled_mts, X_fault_scaled_mts, scaler = None, None, None\n",
        "    try:\n",
        "        X_scaled_mts, X_fault_scaled_mts, scaler = load_and_preprocess_data(SYSTEM, RAW_DATA_DIR)\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Skipping model execution due to data loading failure: {e}\")\n",
        "        # exit() # Use a placeholder or small dummy data to allow testing the code structure\n",
        "        X_scaled_mts = np.random.rand(800 * 200, N_FEATURES)\n",
        "        X_fault_scaled_mts = np.random.rand(200 * 200, N_FEATURES)\n",
        "        print(\"Using fallback dummy data for execution.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unknown error occurred during data loading: {e}\")\n",
        "        # exit() # Use a placeholder or small dummy data to allow testing the code structure\n",
        "        X_scaled_mts = np.random.rand(800 * 200, N_FEATURES)\n",
        "        X_fault_scaled_mts = np.random.rand(200 * 200, N_FEATURES)\n",
        "        print(\"Using fallback dummy data for execution.\")\n",
        "\n",
        "    # Simple split of normal data into training (first 80%) and testing (last 20%)\n",
        "    split_idx = int(len(X_scaled_mts) * 0.8)\n",
        "    X_train_mts = X_scaled_mts[:split_idx]\n",
        "    X_normal_test_mts_full = X_scaled_mts[split_idx:]\n",
        "    X_normal_test_mts = X_normal_test_mts_full[:18999]\n",
        "    X_fault_scaled_mts = X_fault_scaled_mts[:999]\n",
        "\n",
        "    # Custom Sampling for test data to mirror previous setup\n",
        "    # Ensure test data is long enough to form windows\n",
        "    X_normal_test_mts = X_normal_test_mts_full[:max(len(X_normal_test_mts_full) - WINDOW_SIZE, WINDOW_SIZE * 5)]\n",
        "    X_fault_scaled_mts = X_fault_scaled_mts[:max(len(X_fault_scaled_mts) - WINDOW_SIZE, WINDOW_SIZE * 5)]\n",
        "\n",
        "    # 2. Create windowed datasets for training\n",
        "    X_train_win, Y_train_win = create_windows(X_train_mts, WINDOW_SIZE, PREDICTION_LENGTH)\n",
        "\n",
        "    # Create the PyTorch DataLoader\n",
        "    train_dataset = TimeSeriesDataset(X_train_win, Y_train_win)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    # 3. Initialize Model, Loss, and Optimizer\n",
        "    model = GanomalyModel(\n",
        "        input_size=N_FEATURES,\n",
        "        hidden_size=GRU_HIDDEN_SIZE,\n",
        "        latent_dim=LATENT_DIM,\n",
        "        seq_len=WINDOW_SIZE\n",
        "    ).to(device)\n",
        "\n",
        "    # 4. Train the model\n",
        "    start_time = time.time()\n",
        "    # The train function internally defines and uses the optimizers based on global LR,\n",
        "    # but we are passing the model and dataloader.\n",
        "    train_ganomaly(model, train_dataloader, device, N_EPOCHS)\n",
        "    end_time = time.time()\n",
        "    print(f\"Total training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "    # 5. Run the core experiment: Evaluate Missing Modalities\n",
        "    missing_modalities_count = 5\n",
        "\n",
        "    normal_full_scores, fault_full_scores, normal_missing_scores, fault_missing_scores = evaluate_ganomaly(\n",
        "        model,\n",
        "        X_normal_test_mts,\n",
        "        X_fault_scaled_mts,\n",
        "        WINDOW_SIZE,\n",
        "        missing_modalities_count=missing_modalities_count,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # 6. Calculate AUC and Youden's J for both scenarios\n",
        "    calculate_youden_auc(normal_full_scores, fault_full_scores, \"Full Modalities Test (Ganomaly)\")\n",
        "    calculate_youden_auc(normal_missing_scores, fault_missing_scores, f\"Missing {missing_modalities_count} Modalities Test (Ganomaly)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ba_BRQG_Y4r",
        "outputId": "0d548945-aea9-4176-866d-d73f655809af"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading data for system: RFQ\n",
            "Real data loaded successfully.\n",
            "Normal Data Pulses: 690, Fault Data Pulses: 182\n",
            "Concatenated and Scaled MTS shape: (3105000, 14)\n",
            "Created 2483901 windows of size 100.\n",
            "\n",
            "Starting Ganomaly Training on device: cuda\n",
            "Epoch 010/30, G Loss: 0.069328, D Loss: 1.386293\n",
            "Epoch 020/30, G Loss: 0.069323, D Loss: 1.386293\n",
            "Epoch 030/30, G Loss: 0.069321, D Loss: 1.386294\n",
            "Ganomaly Training complete.\n",
            "Total training time: 3501.18 seconds\n",
            "\n",
            "Starting Ganomaly Evaluation...\n",
            "Created 620801 windows of size 100.\n",
            "Finished processing 620801 Normal windows.\n",
            "Created 800 windows of size 100.\n",
            "Finished processing 800 Fault windows.\n",
            "\n",
            "--- CLASSIFICATION METRICS: Full Modalities Test (Ganomaly) ---\n",
            "AUC-ROC Score: 0.9993\n",
            "Optimal Threshold (Youden's J): 0.000063\n",
            "Accuracy: 0.9993\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.9993\n",
            "Youden's J Max Value: 0.9993\n",
            "\n",
            "--- CLASSIFICATION METRICS: Missing 5 Modalities Test (Ganomaly) ---\n",
            "AUC-ROC Score: 0.0466\n",
            "Optimal Threshold (Youden's J): 0.138554\n",
            "Accuracy: 0.0473\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.0461\n",
            "Youden's J Max Value: 0.0461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_ganomaly(model, X_normal_test_mts, X_fault_test_mts, window_size, missing_modalities_count, device):\n",
        "    \"\"\"\n",
        "    Calculates the Ganomaly score for both normal and fault test data under two conditions:\n",
        "      - Full modalities\n",
        "      - Missing modalities (first `missing_modalities_count` features zeroed)\n",
        "\n",
        "    Anomaly Score = ALPHA * L_rec + GAMMA * L_enc\n",
        "\n",
        "    Returns:\n",
        "        normal_full_scores      : np.array, scores on normal data (all modalities present)\n",
        "        fault_full_scores       : np.array, scores on fault data (all modalities present)\n",
        "        normal_missing_scores   : np.array, scores on normal data (with missing modalities)\n",
        "        fault_missing_scores    : np.array, scores on fault data (with missing modalities)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    mse_criterion = nn.MSELoss(reduction='none')\n",
        "\n",
        "    normal_full_scores = []\n",
        "    fault_full_scores = []\n",
        "    normal_missing_scores = []\n",
        "    fault_missing_scores = []\n",
        "\n",
        "    print(\"\\nStarting Ganomaly Evaluation...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Evaluate for Normal and Fault sets\n",
        "        for name, X_mts in [('Normal', X_normal_test_mts), ('Fault', X_fault_test_mts)]:\n",
        "\n",
        "            # Create windows on the MTS data (same as before)\n",
        "            X_win_eval, Y_win_eval = create_windows(X_mts, window_size, PREDICTION_LENGTH)\n",
        "\n",
        "            if len(X_win_eval) == 0:\n",
        "                print(f\"Warning: No {name} test windows provided. Skipping evaluation.\")\n",
        "                continue\n",
        "\n",
        "            test_dataset = TimeSeriesDataset(X_win_eval, Y_win_eval)\n",
        "            test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "            current_scores_full = []\n",
        "            current_scores_missing = []\n",
        "\n",
        "            for batch_x, _ in test_dataloader:\n",
        "                batch_x = batch_x.to(device)  # shape: (B, T, F)\n",
        "\n",
        "                # -----------------------------\n",
        "                # 1) Full Modality Evaluation\n",
        "                # -----------------------------\n",
        "                reconstruction_full, z_original_full = model.G(batch_x)\n",
        "                z_reconstructed_full = model.encode_reconstruction(reconstruction_full)\n",
        "\n",
        "                # L_rec_full: MSE over all features and timesteps\n",
        "                l_rec_full = mse_criterion(reconstruction_full, batch_x).mean(dim=(1, 2))\n",
        "\n",
        "                # L_enc_full: MSE in latent space\n",
        "                l_enc_full = mse_criterion(z_reconstructed_full, z_original_full).mean(dim=1)\n",
        "\n",
        "                score_full = (ALPHA * l_rec_full) + (GAMMA * l_enc_full)\n",
        "                current_scores_full.extend(score_full.detach().cpu().numpy())\n",
        "\n",
        "                # -----------------------------\n",
        "                # 2) Missing Modality Evaluation\n",
        "                # -----------------------------\n",
        "                if missing_modalities_count > 0:\n",
        "                    # Clamp missing count to number of available features\n",
        "                    num_features = batch_x.size(2)\n",
        "                    miss = min(missing_modalities_count, num_features)\n",
        "\n",
        "                    # Build mask: 1 = keep, 0 = missing\n",
        "                    mask = torch.ones_like(batch_x)\n",
        "                    mask[:, :, :miss] = 0.0\n",
        "\n",
        "                    # Masked input (simulate missing modalities)\n",
        "                    X_missing = batch_x * mask\n",
        "\n",
        "                    reconstruction_missing, z_original_missing = model.G(X_missing)\n",
        "                    z_reconstructed_missing = model.encode_reconstruction(reconstruction_missing)\n",
        "\n",
        "                    # --- Reconstruction loss only on *unmasked* (available) features ---\n",
        "                    diff_sq = (reconstruction_missing - batch_x) ** 2 * mask\n",
        "                    # Normalize by number of unmasked elements per sample\n",
        "                    mask_sum = mask.sum(dim=(1, 2)).clamp_min(1.0)\n",
        "                    l_rec_missing = diff_sq.sum(dim=(1, 2)) / mask_sum\n",
        "\n",
        "                    # Latent consistency loss (both latents come from masked pipeline)\n",
        "                    l_enc_missing = mse_criterion(z_reconstructed_missing, z_original_missing).mean(dim=1)\n",
        "\n",
        "                    score_missing = (ALPHA * l_rec_missing) + (GAMMA * l_enc_missing)\n",
        "                    current_scores_missing.extend(score_missing.detach().cpu().numpy())\n",
        "                else:\n",
        "                    # If no modalities are missing, missing-score == full-score\n",
        "                    current_scores_missing.extend(score_full.detach().cpu().numpy())\n",
        "\n",
        "            if name == 'Normal':\n",
        "                normal_full_scores.extend(current_scores_full)\n",
        "                normal_missing_scores.extend(current_scores_missing)\n",
        "            else:  # 'Fault'\n",
        "                fault_full_scores.extend(current_scores_full)\n",
        "                fault_missing_scores.extend(current_scores_missing)\n",
        "\n",
        "            print(f\"Finished processing {len(X_win_eval)} {name} windows.\")\n",
        "\n",
        "    return (np.array(normal_full_scores),\n",
        "            np.array(fault_full_scores),\n",
        "            np.array(normal_missing_scores),\n",
        "            np.array(fault_missing_scores))\n"
      ],
      "metadata": {
        "id": "LRXUO3eVoUyM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # 5. Run the core experiment: Evaluate Missing Modalities\n",
        "missing_modalities_count = 1\n",
        "\n",
        "normal_full_scores, fault_full_scores, normal_missing_scores, fault_missing_scores = evaluate_ganomaly(\n",
        "        model,\n",
        "        X_normal_test_mts,\n",
        "        X_fault_scaled_mts,\n",
        "        WINDOW_SIZE,\n",
        "        missing_modalities_count=missing_modalities_count,\n",
        "        device=device\n",
        ")\n",
        "\n",
        "calculate_youden_auc(normal_full_scores, fault_full_scores, \"Full Modalities Test (Ganomaly)\")\n",
        "calculate_youden_auc(normal_missing_scores, fault_missing_scores, f\"Missing {missing_modalities_count} Modalities Test (Ganomaly)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bARgVZ-pjpc",
        "outputId": "6afb631f-7e15-4e2e-aac8-6a877a763878"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Ganomaly Evaluation...\n",
            "Created 620801 windows of size 100.\n",
            "Finished processing 620801 Normal windows.\n",
            "Created 800 windows of size 100.\n",
            "Finished processing 800 Fault windows.\n",
            "\n",
            "--- CLASSIFICATION METRICS: Full Modalities Test (Ganomaly) ---\n",
            "AUC-ROC Score: 0.9993\n",
            "Optimal Threshold (Youden's J): 0.000063\n",
            "Accuracy: 0.9993\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.9993\n",
            "Youden's J Max Value: 0.9993\n",
            "\n",
            "--- CLASSIFICATION METRICS: Missing 1 Modalities Test (Ganomaly) ---\n",
            "AUC-ROC Score: 0.9536\n",
            "Optimal Threshold (Youden's J): 0.000098\n",
            "Accuracy: 0.9527\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.9526\n",
            "Youden's J Max Value: 0.9526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # 5. Run the core experiment: Evaluate Missing Modalities\n",
        "missing_modalities_count = 2\n",
        "\n",
        "normal_full_scores, fault_full_scores, normal_missing_scores, fault_missing_scores = evaluate_ganomaly(\n",
        "        model,\n",
        "        X_normal_test_mts,\n",
        "        X_fault_scaled_mts,\n",
        "        WINDOW_SIZE,\n",
        "        missing_modalities_count=missing_modalities_count,\n",
        "        device=device\n",
        ")\n",
        "\n",
        "calculate_youden_auc(normal_full_scores, fault_full_scores, \"Full Modalities Test (Ganomaly)\")\n",
        "calculate_youden_auc(normal_missing_scores, fault_missing_scores, f\"Missing {missing_modalities_count} Modalities Test (Ganomaly)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FVs3A9koZI_",
        "outputId": "be5afa19-5b88-4472-ee40-216f7f5f2409"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Ganomaly Evaluation...\n",
            "Created 620801 windows of size 100.\n",
            "Finished processing 620801 Normal windows.\n",
            "Created 800 windows of size 100.\n",
            "Finished processing 800 Fault windows.\n",
            "\n",
            "--- CLASSIFICATION METRICS: Full Modalities Test (Ganomaly) ---\n",
            "AUC-ROC Score: 0.9993\n",
            "Optimal Threshold (Youden's J): 0.000063\n",
            "Accuracy: 0.9993\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.9993\n",
            "Youden's J Max Value: 0.9993\n",
            "\n",
            "--- CLASSIFICATION METRICS: Missing 2 Modalities Test (Ganomaly) ---\n",
            "AUC-ROC Score: 0.9421\n",
            "Optimal Threshold (Youden's J): 0.000143\n",
            "Accuracy: 0.9419\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.9419\n",
            "Youden's J Max Value: 0.9419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # 5. Run the core experiment: Evaluate Missing Modalities\n",
        "missing_modalities_count = 3\n",
        "\n",
        "normal_full_scores, fault_full_scores, normal_missing_scores, fault_missing_scores = evaluate_ganomaly(\n",
        "        model,\n",
        "        X_normal_test_mts,\n",
        "        X_fault_scaled_mts,\n",
        "        WINDOW_SIZE,\n",
        "        missing_modalities_count=missing_modalities_count,\n",
        "        device=device\n",
        ")\n",
        "\n",
        "calculate_youden_auc(normal_full_scores, fault_full_scores, \"Full Modalities Test (Ganomaly)\")\n",
        "calculate_youden_auc(normal_missing_scores, fault_missing_scores, f\"Missing {missing_modalities_count} Modalities Test (Ganomaly)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KFqm931pnl_",
        "outputId": "8ddc53a8-f3d7-49e1-e285-8a2700c51aa6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Ganomaly Evaluation...\n",
            "Created 620801 windows of size 100.\n",
            "Finished processing 620801 Normal windows.\n",
            "Created 800 windows of size 100.\n",
            "Finished processing 800 Fault windows.\n",
            "\n",
            "--- CLASSIFICATION METRICS: Full Modalities Test (Ganomaly) ---\n",
            "AUC-ROC Score: 0.9993\n",
            "Optimal Threshold (Youden's J): 0.000063\n",
            "Accuracy: 0.9993\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.9993\n",
            "Youden's J Max Value: 0.9993\n",
            "\n",
            "--- CLASSIFICATION METRICS: Missing 3 Modalities Test (Ganomaly) ---\n",
            "AUC-ROC Score: 0.9811\n",
            "Optimal Threshold (Youden's J): 0.000341\n",
            "Accuracy: 0.9805\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.9805\n",
            "Youden's J Max Value: 0.9805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # 5. Run the core experiment: Evaluate Missing Modalities\n",
        "missing_modalities_count = 4\n",
        "\n",
        "normal_full_scores, fault_full_scores, normal_missing_scores, fault_missing_scores = evaluate_ganomaly(\n",
        "        model,\n",
        "        X_normal_test_mts,\n",
        "        X_fault_scaled_mts,\n",
        "        WINDOW_SIZE,\n",
        "        missing_modalities_count=missing_modalities_count,\n",
        "        device=device\n",
        ")\n",
        "\n",
        "calculate_youden_auc(normal_full_scores, fault_full_scores, \"Full Modalities Test (Ganomaly)\")\n",
        "calculate_youden_auc(normal_missing_scores, fault_missing_scores, f\"Missing {missing_modalities_count} Modalities Test (Ganomaly)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dP5v9nhppYR",
        "outputId": "cb5be0da-aac5-4a8e-871c-3b16d212e05f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Ganomaly Evaluation...\n",
            "Created 620801 windows of size 100.\n",
            "Finished processing 620801 Normal windows.\n",
            "Created 800 windows of size 100.\n",
            "Finished processing 800 Fault windows.\n",
            "\n",
            "--- CLASSIFICATION METRICS: Full Modalities Test (Ganomaly) ---\n",
            "AUC-ROC Score: 0.9993\n",
            "Optimal Threshold (Youden's J): 0.000063\n",
            "Accuracy: 0.9993\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.9993\n",
            "Youden's J Max Value: 0.9993\n",
            "\n",
            "--- CLASSIFICATION METRICS: Missing 4 Modalities Test (Ganomaly) ---\n",
            "AUC-ROC Score: 0.6749\n",
            "Optimal Threshold (Youden's J): 0.000186\n",
            "Accuracy: 0.6753\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.6748\n",
            "Youden's J Max Value: 0.6748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # 5. Run the core experiment: Evaluate Missing Modalities\n",
        "missing_modalities_count = 5\n",
        "\n",
        "normal_full_scores, fault_full_scores, normal_missing_scores, fault_missing_scores = evaluate_ganomaly(\n",
        "        model,\n",
        "        X_normal_test_mts,\n",
        "        X_fault_scaled_mts,\n",
        "        WINDOW_SIZE,\n",
        "        missing_modalities_count=missing_modalities_count,\n",
        "        device=device\n",
        ")\n",
        "\n",
        "calculate_youden_auc(normal_full_scores, fault_full_scores, \"Full Modalities Test (Ganomaly)\")\n",
        "calculate_youden_auc(normal_missing_scores, fault_missing_scores, f\"Missing {missing_modalities_count} Modalities Test (Ganomaly)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOaPR4i-prgO",
        "outputId": "235a8477-69df-4a5b-829c-3bdaab6f4d1d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Ganomaly Evaluation...\n",
            "Created 620801 windows of size 100.\n",
            "Finished processing 620801 Normal windows.\n",
            "Created 800 windows of size 100.\n",
            "Finished processing 800 Fault windows.\n",
            "\n",
            "--- CLASSIFICATION METRICS: Full Modalities Test (Ganomaly) ---\n",
            "AUC-ROC Score: 0.9993\n",
            "Optimal Threshold (Youden's J): 0.000063\n",
            "Accuracy: 0.9993\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.9993\n",
            "Youden's J Max Value: 0.9993\n",
            "\n",
            "--- CLASSIFICATION METRICS: Missing 5 Modalities Test (Ganomaly) ---\n",
            "AUC-ROC Score: 0.6136\n",
            "Optimal Threshold (Youden's J): 0.000127\n",
            "Accuracy: 0.6106\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.6101\n",
            "Youden's J Max Value: 0.6101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # 5. Run the core experiment: Evaluate Missing Modalities\n",
        "missing_modalities_count = 6\n",
        "\n",
        "normal_full_scores, fault_full_scores, normal_missing_scores, fault_missing_scores = evaluate_ganomaly(\n",
        "        model,\n",
        "        X_normal_test_mts,\n",
        "        X_fault_scaled_mts,\n",
        "        WINDOW_SIZE,\n",
        "        missing_modalities_count=missing_modalities_count,\n",
        "        device=device\n",
        ")\n",
        "\n",
        "calculate_youden_auc(normal_full_scores, fault_full_scores, \"Full Modalities Test (Ganomaly)\")\n",
        "calculate_youden_auc(normal_missing_scores, fault_missing_scores, f\"Missing {missing_modalities_count} Modalities Test (Ganomaly)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKuEGMsOpue6",
        "outputId": "25453f1a-368e-43e8-9e8c-ce5976d44e52"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Ganomaly Evaluation...\n",
            "Created 620801 windows of size 100.\n",
            "Finished processing 620801 Normal windows.\n",
            "Created 800 windows of size 100.\n",
            "Finished processing 800 Fault windows.\n",
            "\n",
            "--- CLASSIFICATION METRICS: Full Modalities Test (Ganomaly) ---\n",
            "AUC-ROC Score: 0.9993\n",
            "Optimal Threshold (Youden's J): 0.000063\n",
            "Accuracy: 0.9993\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.9993\n",
            "Youden's J Max Value: 0.9993\n",
            "\n",
            "--- CLASSIFICATION METRICS: Missing 6 Modalities Test (Ganomaly) ---\n",
            "AUC-ROC Score: 0.6732\n",
            "Optimal Threshold (Youden's J): 0.000334\n",
            "Accuracy: 0.6736\n",
            "Sensitivity (TPR): 1.0000\n",
            "Specificity (TNR): 0.6731\n",
            "Youden's J Max Value: 0.6731\n"
          ]
        }
      ]
    }
  ]
}